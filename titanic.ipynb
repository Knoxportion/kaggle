{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import random\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.ml  import Pipeline     \n",
    "from pyspark.sql import SQLContext  \n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('recommender_system').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender_submission.csv', 'movie_ratings_df.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "entries = os.listdir('C:\\\\Users\\GUEN999\\Desktop\\Data engineer\\kaggle\\dataset')\n",
    "print(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId         title  rating\n",
       "0     196  Kolya (1996)       3\n",
       "1      63  Kolya (1996)       3\n",
       "2     226  Kolya (1996)       5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset and create sprk dataframe\n",
    "df=spark.read.csv('C:\\\\Users\\GUEN999\\Desktop\\Data engineer\\kaggle\\dataset\\movie_ratings_df.csv',inferSchema=True,header=True)\n",
    "# Using limit(), or select() or show() to view the data. I often use limit()\n",
    "# Using toPandas() method to return Pyspark DataFrame as Pandas table\n",
    "df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+------+\n",
      "|userId|       title|rating|\n",
      "+------+------------+------+\n",
      "|   196|Kolya (1996)|     3|\n",
      "|    63|Kolya (1996)|     3|\n",
      "|   226|Kolya (1996)|     5|\n",
      "|   154|Kolya (1996)|     3|\n",
      "|   306|Kolya (1996)|     5|\n",
      "|   296|Kolya (1996)|     4|\n",
      "|    34|Kolya (1996)|     5|\n",
      "|   271|Kolya (1996)|     4|\n",
      "|   201|Kolya (1996)|     4|\n",
      "|   209|Kolya (1996)|     4|\n",
      "|    35|Kolya (1996)|     2|\n",
      "|   354|Kolya (1996)|     5|\n",
      "|   199|Kolya (1996)|     5|\n",
      "|   113|Kolya (1996)|     2|\n",
      "|     1|Kolya (1996)|     5|\n",
      "|   173|Kolya (1996)|     5|\n",
      "|   360|Kolya (1996)|     4|\n",
      "|   234|Kolya (1996)|     4|\n",
      "|    14|Kolya (1996)|     4|\n",
      "|   309|Kolya (1996)|     4|\n",
      "+------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
